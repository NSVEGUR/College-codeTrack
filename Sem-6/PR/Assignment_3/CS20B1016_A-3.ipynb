{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0917bf5",
   "metadata": {},
   "source": [
    "# Pattern Recognition\n",
    "----\n",
    "`Roll: CS20B1016, Name: V Nagasai`\n",
    "\n",
    "----\n",
    "## Assignment-3\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a3918",
   "metadata": {},
   "source": [
    "## QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4929c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8802e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gender.csv')\n",
    "matrix = np.array(df.drop(['id', 'gender'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a207c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(matrix.T)\n",
    "eigval, eigvec = np.linalg.eig(cov)\n",
    "\n",
    "zipped = list(zip(eigval, eigvec))\n",
    "sort = sorted(zipped, key=lambda x: x[0])\n",
    "e = []\n",
    "for i in range(len(sort)):\n",
    "    e.append((sort[i][1]).tolist())\n",
    "\n",
    "def selectDimension(eigenvalues):\n",
    "    summed = np.sum(eigenvalues)\n",
    "    l = []\n",
    "    for i in eigenvalues:\n",
    "        l.append(i)\n",
    "        if(np.sum(l)/summed >= 0.95):\n",
    "            break\n",
    "    return len(l)\n",
    "\n",
    "eigval_dimsake = np.sort(abs(eigval))[::-1]\n",
    "dim = selectDimension(eigval_dimsake.tolist())\n",
    "e = e[128-dim:]\n",
    "eig = np.array(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9f0337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020663</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>0.025896</td>\n",
       "      <td>0.077745</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>-0.019544</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.045180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>0.050108</td>\n",
       "      <td>-0.042359</td>\n",
       "      <td>-0.043169</td>\n",
       "      <td>0.072197</td>\n",
       "      <td>-0.030286</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>-0.012514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081086</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>0.066882</td>\n",
       "      <td>-0.025894</td>\n",
       "      <td>-0.040827</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>-0.054452</td>\n",
       "      <td>0.046362</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009627</td>\n",
       "      <td>-0.009198</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.059826</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>-0.027541</td>\n",
       "      <td>-0.031170</td>\n",
       "      <td>-0.037413</td>\n",
       "      <td>0.029172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>-0.108151</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.016072</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.070117</td>\n",
       "      <td>-0.004264</td>\n",
       "      <td>-0.024056</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>-0.023523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123613</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>-0.009533</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>-0.088573</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>-0.028842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.060169</td>\n",
       "      <td>-0.028918</td>\n",
       "      <td>-0.027723</td>\n",
       "      <td>-0.058267</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>-0.010291</td>\n",
       "      <td>-0.019561</td>\n",
       "      <td>-0.022930</td>\n",
       "      <td>-0.070139</td>\n",
       "      <td>-0.034139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036594</td>\n",
       "      <td>-0.048974</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>-0.077676</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>-0.035335</td>\n",
       "      <td>-0.048585</td>\n",
       "      <td>0.109378</td>\n",
       "      <td>-0.020485</td>\n",
       "      <td>0.012033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.018169</td>\n",
       "      <td>0.071672</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>-0.078963</td>\n",
       "      <td>-0.041256</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>-0.045944</td>\n",
       "      <td>-0.095732</td>\n",
       "      <td>0.018201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101920</td>\n",
       "      <td>0.063211</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>-0.081042</td>\n",
       "      <td>0.082088</td>\n",
       "      <td>0.096606</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>0.020299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.047032</td>\n",
       "      <td>-0.050970</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>-0.053952</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.039690</td>\n",
       "      <td>-0.055023</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>-0.031778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015631</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>-0.043858</td>\n",
       "      <td>-0.024856</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>-0.047006</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.024061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.037156</td>\n",
       "      <td>-0.038881</td>\n",
       "      <td>-0.027349</td>\n",
       "      <td>-0.066276</td>\n",
       "      <td>0.053607</td>\n",
       "      <td>-0.007637</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>-0.058943</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100616</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.012321</td>\n",
       "      <td>-0.021873</td>\n",
       "      <td>-0.004497</td>\n",
       "      <td>0.066519</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>-0.044594</td>\n",
       "      <td>-0.019770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.038180</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>0.057991</td>\n",
       "      <td>-0.052605</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>0.090918</td>\n",
       "      <td>-0.042361</td>\n",
       "      <td>0.059767</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>-0.032043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050954</td>\n",
       "      <td>0.068721</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>-0.003764</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>-0.046273</td>\n",
       "      <td>-0.030726</td>\n",
       "      <td>-0.095815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.116321</td>\n",
       "      <td>0.026280</td>\n",
       "      <td>-0.025598</td>\n",
       "      <td>-0.023880</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.123827</td>\n",
       "      <td>0.039479</td>\n",
       "      <td>0.039621</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020816</td>\n",
       "      <td>-0.042410</td>\n",
       "      <td>-0.083033</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>-0.009023</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>-0.032110</td>\n",
       "      <td>-0.043728</td>\n",
       "      <td>-0.001396</td>\n",
       "      <td>0.021098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.084819</td>\n",
       "      <td>-0.010271</td>\n",
       "      <td>-0.036148</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>-0.016490</td>\n",
       "      <td>0.126778</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>-0.103837</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082714</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>-0.027693</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>-0.084399</td>\n",
       "      <td>-0.050908</td>\n",
       "      <td>-0.014413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.020663  0.059296  0.025896  0.077745  0.040112  0.024903 -0.019544   \n",
       "1   -0.081086 -0.035615  0.066882 -0.025894 -0.040827  0.017899 -0.054452   \n",
       "2    0.000325 -0.108151  0.037087  0.016072  0.041832  0.070117 -0.004264   \n",
       "3   -0.060169 -0.028918 -0.027723 -0.058267  0.001034 -0.010291 -0.019561   \n",
       "4   -0.006898 -0.018169  0.071672  0.006226 -0.078963 -0.041256 -0.005951   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "795  0.047032 -0.050970  0.030024 -0.053952  0.063199  0.039690 -0.055023   \n",
       "796  0.064583  0.037156 -0.038881 -0.027349 -0.066276  0.053607 -0.007637   \n",
       "797  0.038180  0.029432  0.057991 -0.052605  0.069466  0.090918 -0.042361   \n",
       "798  0.116321  0.026280 -0.025598 -0.023880 -0.000049 -0.123827  0.039479   \n",
       "799  0.084819 -0.010271 -0.036148  0.022474 -0.016490  0.126778  0.040282   \n",
       "\n",
       "           7         8         9   ...        47        48        49  \\\n",
       "0   -0.016834  0.006344  0.045180  ...  0.038573 -0.003400  0.050108   \n",
       "1    0.046362 -0.005593  0.038651  ... -0.009627 -0.009198  0.035749   \n",
       "2   -0.024056 -0.085705 -0.023523  ...  0.123613  0.001586  0.013978   \n",
       "3   -0.022930 -0.070139 -0.034139  ...  0.036594 -0.048974 -0.002267   \n",
       "4   -0.045944 -0.095732  0.018201  ...  0.101920  0.063211 -0.068600   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.014964  0.027501 -0.031778  ... -0.015631  0.038323 -0.009356   \n",
       "796  0.053608 -0.058943  0.026878  ... -0.100616 -0.001057 -0.012321   \n",
       "797  0.059767  0.008892 -0.032043  ... -0.050954  0.068721  0.015490   \n",
       "798  0.039621  0.045593  0.013405  ... -0.020816 -0.042410 -0.083033   \n",
       "799  0.016242 -0.103837  0.001251  ... -0.082714  0.020437 -0.027693   \n",
       "\n",
       "           50        51        52        53        54        55        56  \n",
       "0   -0.042359 -0.043169  0.072197 -0.030286  0.031919  0.033483 -0.012514  \n",
       "1    0.059826  0.095480  0.035620 -0.027541 -0.031170 -0.037413  0.029172  \n",
       "2    0.018897 -0.009533 -0.001712  0.021702 -0.088573  0.113828 -0.028842  \n",
       "3   -0.077676  0.031133 -0.035335 -0.048585  0.109378 -0.020485  0.012033  \n",
       "4   -0.081042  0.082088  0.096606  0.004918 -0.018458 -0.000878  0.020299  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795  0.039324 -0.043858 -0.024856  0.025050 -0.047006  0.035764  0.024061  \n",
       "796 -0.021873 -0.004497  0.066519  0.033036  0.009875 -0.044594 -0.019770  \n",
       "797  0.026731 -0.003764  0.015751  0.010004 -0.046273 -0.030726 -0.095815  \n",
       "798 -0.004348 -0.009023 -0.002458 -0.032110 -0.043728 -0.001396  0.021098  \n",
       "799  0.022399  0.011763  0.044259  0.033526 -0.084399 -0.050908 -0.014413  \n",
       "\n",
       "[800 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meaned = np.mean(matrix, 0)\n",
    "Y = np.matmul(eig, (matrix-meaned).T).T\n",
    "new = pd.DataFrame(Y)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed5e76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE PCA CONFUSION MATRIX WITH CLASES 'MALE' & 'FEMALE: ' 70.0 % WHEN MINIMUM DISTANCE CLASSIFIER IS USED\n"
     ]
    }
   ],
   "source": [
    "new = np.array(new)\n",
    "maletrain = new[11:401, :]\n",
    "femaletrain = new[411:800, :]\n",
    "\n",
    "maletest = new[0:10,:]\n",
    "femaletest = new[401:411,:]\n",
    "\n",
    "malecov = np.cov(maletrain.T)\n",
    "femalecov = np.cov(femaletrain.T)\n",
    "\n",
    "malemean = np.mean(maletrain, 0)\n",
    "femalemean = np.mean(femaletrain, 0)\n",
    "\n",
    "truemale = 0\n",
    "truefemale = 0\n",
    "falsemale = 0\n",
    "falsefemale = 0\n",
    "for i in range(10):\n",
    "#For MALE\n",
    "    dmm = np.matmul(np.matmul((np.subtract(maletest[i,:], malemean)).T, malecov), np.subtract(maletest[i,:], malemean))\n",
    "    dfm = np.matmul(np.matmul((np.subtract(maletest[i,:], femalemean)).T, femalecov), np.subtract(maletest[i,:], femalemean))\n",
    "    if dmm<dfm:\n",
    "        truemale+=1\n",
    "    else:\n",
    "        falsemale+=1\n",
    "#For FEMALE\n",
    "for i in range(10):\n",
    "    dmf = np.matmul(np.matmul((np.subtract(femaletest[i,:], malemean)).T, malecov), np.subtract(femaletest[i,:], malemean))\n",
    "    dff = np.matmul(np.matmul((np.subtract(femaletest[i,:], femalemean)).T, femalecov), np.subtract(femaletest[i,:], femalemean))\n",
    "    if dmf>dff:\n",
    "        truefemale+=1\n",
    "    else:\n",
    "        falsefemale+=1\n",
    "print(\"ACCURACY OF THE PCA CONFUSION MATRIX WITH CLASES 'MALE' & 'FEMALE: '\",(truemale+truefemale)*100/(20),\"%\", \"WHEN MINIMUM DISTANCE CLASSIFIER IS USED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d54426",
   "metadata": {},
   "source": [
    "## QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8c8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 128)\n",
      "ACCURACY OF THE LDA CONFUSION MATRIX WITH CLASES 'MALE' & 'FEMALE: ' 55.0\n"
     ]
    }
   ],
   "source": [
    "male = matrix[:400,:]\n",
    "female = matrix[400:,:]\n",
    "\n",
    "malescatter = (matrix.shape[0]-1)*np.cov(male.T)\n",
    "femalescatter = (matrix.shape[0]-1)*np.cov(female.T)\n",
    "\n",
    "Sw = malescatter + femalescatter\n",
    "means = np.matrix(np.mean(male,0) - np.mean(female, 0))\n",
    "Sb = np.matmul(means.T, means)\n",
    "eigval, eigvec = np.linalg.eig(Sb)\n",
    "eigval_dimsake = np.sort(eigval)[::-1]\n",
    "zipped = list(zip(eigval, eigvec))\n",
    "sort = sorted(zipped, key=lambda x: x[0])\n",
    "e = []\n",
    "for i in range(len(sort)):\n",
    "    e.append((sort[i][1]).tolist())\n",
    "e = e[128-66:]\n",
    "eig = []\n",
    "for i in range(len(e)):\n",
    "    eig.append(e[len(e)-1-i][0])\n",
    "eig = np.array(eig)\n",
    "print(eig.shape)\n",
    "#PROJECTION\n",
    "male_proj = np.matmul(eig, male.T).T\n",
    "female_proj = np.matmul(eig, female.T).T\n",
    "\n",
    "maletest = male_proj[:10,:]\n",
    "femaletest = female_proj[:10,:]\n",
    "\n",
    "maletrain = male_proj[10:,:]\n",
    "femaletrain = female_proj[10:,:]\n",
    "\n",
    "malemean = np.mean(maletrain, 0)\n",
    "malecov = np.cov(maletrain.T)\n",
    "femalemean = np.mean(femaletrain, 0)\n",
    "femalecov = np.cov(femaletrain.T)\n",
    "\n",
    "truemale_lda = 0\n",
    "truefemale_lda = 0\n",
    "falsemale_lda = 0\n",
    "falsefemale_lda = 0\n",
    "\n",
    "for i in range(10):\n",
    "    dmm = np.matmul(np.matmul((maletest[i, :]-malemean).T, malecov), (maletest[i,:]-malemean))\n",
    "    dmf = np.matmul(np.matmul((maletest[i, :]-femalemean).T, femalecov), (maletest[i,:]-femalemean))\n",
    "    if dmm<dmf:\n",
    "        truemale_lda+=1\n",
    "    else:\n",
    "        falsemale_lda+=1\n",
    "    \n",
    "    dfm = np.matmul(np.matmul((femaletest[i, :]-malemean).T, malecov), (femaletest[i,:]-malemean))\n",
    "    dff = np.matmul(np.matmul((femaletest[i, :]-femalemean).T, femalecov), (femaletest[i,:]-femalemean))\n",
    "    if dff<dfm:\n",
    "        truefemale_lda+=1\n",
    "    else:\n",
    "        falsefemale_lda+=1\n",
    "print(\"ACCURACY OF THE LDA CONFUSION MATRIX WITH CLASES 'MALE' & 'FEMALE: '\",(truemale_lda+truefemale_lda)*100/(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68daf258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX FOR PCA:\n",
      "ACTUAL CLASSIFICATION ===>\n",
      "CLASSIFIED BY PCA \n",
      "        MALE    FEMALE\n",
      "MALE     9     5\n",
      "FEMALE   1      5\n",
      "-------------------------------------------------------\n",
      "CONFUSION MATRIX FOR LDA:\n",
      "ACTUAL CLASSIFICATION ===>\n",
      "CLASSIFIED BY PCA \n",
      "        MALE    FEMALE\n",
      "MALE     6     5\n",
      "FEMALE   4      5\n"
     ]
    }
   ],
   "source": [
    "print(\"CONFUSION MATRIX FOR PCA:\")\n",
    "print(\"ACTUAL CLASSIFICATION ===>\")\n",
    "print(\"CLASSIFIED BY PCA \")\n",
    "print(\"        MALE    FEMALE\")\n",
    "print(\"MALE    \",truemale, \"   \", falsefemale)\n",
    "print(\"FEMALE  \",falsemale, \"    \", truefemale)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"CONFUSION MATRIX FOR LDA:\")\n",
    "print(\"ACTUAL CLASSIFICATION ===>\")\n",
    "print(\"CLASSIFIED BY PCA \")\n",
    "print(\"        MALE    FEMALE\")\n",
    "print(\"MALE    \",truemale_lda, \"   \", falsefemale_lda)\n",
    "print(\"FEMALE  \",falsemale_lda, \"    \", truefemale_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47a3c8",
   "metadata": {},
   "source": [
    "## QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3351f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = pd.read_csv('face.csv')\n",
    "feat = face.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c6435c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.array(feat)\n",
    "cov = np.cov(feat.T)\n",
    "eigval, eigvec = np.linalg.eig(cov)\n",
    "eigval_dimsake = np.sort(abs(eigval))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e579b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim4 = selectDimension(eigval_dimsake)\n",
    "zipped = list(zip(eigval, eigvec))\n",
    "e = []\n",
    "sort = sorted(zipped, key=lambda x: x[0])\n",
    "for i in range(len(sort)):\n",
    "    e.append((sort[i][1]).tolist())\n",
    "e = e[4096-dim4:]\n",
    "eig = np.array(e)\n",
    "Y = np.matmul(eig, (feat-np.mean(feat,0)).T)\n",
    "X = pd.DataFrame(Y.T)\n",
    "X['class'] = face['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d9a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = []\n",
    "covs = []\n",
    "for i in range(0,40):\n",
    "    sam = X.loc[X['class'] == i]\n",
    "    s = np.array(sam.drop('class', axis=1))\n",
    "    covs.append(np.cov(s.T))\n",
    "    means.append(np.mean(s,0))\n",
    "\n",
    "def distance(vec, mean, cov):\n",
    "    d = np.matmul(np.matmul((vec-mean), cov), (vec-mean).T)\n",
    "    return d\n",
    "S = X\n",
    "S = S.drop('class', axis=1)\n",
    "data = np.array(S)\n",
    "correct = 0\n",
    "for i in range(400):\n",
    "    dis = []\n",
    "    for j in range(40):\n",
    "        dis.append(distance(data[i][:], means[j], covs[j]))\n",
    "    cl = dis.index(min(dis))\n",
    "    if cl == X['class'][j]:\n",
    "        correct+=1\n",
    "    dis.clear()\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f616dc7",
   "metadata": {},
   "source": [
    "## QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be54edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0674b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.95\n"
     ]
    }
   ],
   "source": [
    "faceData = pd.read_csv('face.csv')\n",
    "faceData.head()\n",
    "faceData['target'].unique()\n",
    "faceData.describe()\n",
    "test_data = faceData.groupby('target').apply(lambda x: x.head(2)).reset_index(drop=True)\n",
    "train_data = faceData.groupby('target').apply(lambda x: x.tail(8)).reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]\n",
    "X_test, y_test = test_data.iloc[:, :-1], test_data.iloc[:, -1]\n",
    "class LDA:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        class_labels = np.unique(y)\n",
    "\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "\n",
    "        SW = np.zeros((n_features, n_features))\n",
    "        SB = np.zeros((n_features, n_features))\n",
    "\n",
    "        for c in class_labels:\n",
    "            X_c = X[y == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            SW += (X_c - mean_c).T.dot((X_c - mean_c))\n",
    "\n",
    "            n_c = X_c.shape[0]\n",
    "            mean_diff = np.array((mean_c - self.mean)).reshape(n_features, 1)\n",
    "            SB += n_c * (mean_diff).dot(mean_diff.T)\n",
    "\n",
    "        A = np.linalg.inv(SW).dot(SB)\n",
    "\n",
    "        self.eigenvalues, self.eigenvectors = np.linalg.eigh(A)\n",
    "\n",
    "        self.eigenvectors = self.eigenvectors.T\n",
    "        idxs = np.argsort(abs(self.eigenvalues))[::-1]\n",
    "        self.eigenvalues = self.eigenvalues[idxs]\n",
    "        self.eigenvectors = self.eigenvectors[idxs]\n",
    "\n",
    "        # Get required eigen vectors\n",
    "        if self.n_components > 0:\n",
    "            # Select a subset from the rearranged Eigenvalue matrix\n",
    "            self.components = self.eigenvectors[:self.n_components]\n",
    "        else:\n",
    "            raise Exception(\"Minimum dimension should be more than 0\")\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Project data\n",
    "        return np.dot(X, self.components.T)\n",
    "\n",
    "\n",
    "# Fitting and predicting\n",
    "lda = LDA(n_components=66)\n",
    "lda.fit(X_train, y_train)\n",
    "X_train_transformed = lda.transform(X_train)\n",
    "X_test_transformed = lda.transform(X_test)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "# Finding accuracy\n",
    "print(\"Accuracy =\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3879a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
